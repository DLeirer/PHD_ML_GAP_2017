---
title: "Machine Learning"
author: "DJL"
date: "02/10/2016"
output:
  html_document:
    toc: yes
    toc_float: yes
---

#Overview

**Aim**  
Create Machine learning models using GAP data. 

#Old Functions
```{r old functions, tidy=TRUE}
#function for Recursive feature elimination. Requires helper functions below. 
f_rfe_tolist <- function (GX_DF, Resample_list, subsets, control, seed){
  Resample_df<-Resample_list[["DataPartition"]]
  n_repeats<-dim(Resample_df)[2]
  #start loop
  for (i in 1:n_repeats){
    #print loop
    print(paste("Resample ",i))
    #Recursive feature elimination
    #Create Training DF
    train_df<-f_train_test(GX_DF,DataPartition_DF,i,T)
    print(train_df[1:3,1:5])
    #Create Clean DF
    train_df_small<-f_train_clean(train_df,cor_cutoff = 0.75)
    print("Final Train df Size")
    print(dim(train_df_small))
    print(train_df_small[1:3,1:5])
    #Recursive Feature Elmination.
    rfe_output<-f_rfe(train_df_small, subsets, control, seed)
    #get predictors and plot add to lists. 
    Resample_list$rfelist[[i]]<-predictors(rfe_output)
    Resample_list$plottestlist[[i]]<-plot(rfe_output, type = c("g", "o"),col="green",main="Recursive Feature Elimination")
    print("Recursive Feature Elminiation done and Added to list")
  }
  return(Resample_list)
}



#Get train or test DF function # helper function to f_rfe_tolist
f_train_test <- function (Data ,indexDF ,index ,Training = TRUE){
  training_index <- indexDF[,index]  
  if (Training == TRUE){
    print("Training dataframe created")
    training <- Data[training_index,]
    return (training) 
  }else{
    print("Testing dataframe created")
    testing <- Data[-training_index,]
    return (testing)
  }
}



# Clean Training DF function. Correlation and variance.   # helper function to f_rfe_tolist
f_train_clean <- function (train_df, cor_cutoff=0.75,low_variance_cut=0.25){
  ### Remove High correlation probes. 
  #make dataset of features that are not probes for backup and later use.
  highlyCorrelated<-cor_fun(train_df[,-c(1)],cor_cutoff=cor_cutoff)
  # remove highly correlated probes
  train_df<-train_df[,-c(highlyCorrelated+1)]##+1 is for phenotype col. Adds 1 to each number. 
  
  #Low Variance Probes removed
  Gx_vars<-apply(train_df[,c(-1)], 2, function(x) var(x,y = NULL, na.rm = FALSE, "everything"))
  Gx_vars_quant<-quantile(Gx_vars, c(low_variance_cut))
  Gx_vars_names<-names(which(Gx_vars > Gx_vars_quant[1]))
  train_df<-train_df[,c("Phenotype",Gx_vars_names)]
  return(train_df)
}


#Correlation Function # helper function to f_train_clean
cor_fun<- function(gene_exprs_DF,cor_cutoff=0.75) {
  # find highly correlated probes
  correlationMatrix <- cor(gene_exprs_DF)
  # find attributes that are highly corrected (ideally >0.75)
  findCorrelation(correlationMatrix, cutoff=cor_cutoff)
}



#Recursive feature elimination function. # helper function to f_rfe_tolist
f_rfe <- function (train_df_small, subsets, control, seed){
  ### Define Class Labels
  class_labels <- droplevels(as.factor(train_df_small[,1]))
  ## Define Predictors
  gx_predictors=train_df_small[,-1]
  #set seed
  set.seed(seed)
  # run the RFE algorithm
  rfe_output <- rfe(gx_predictors, class_labels, sizes=subsets, rfeControl=control)
  return(rfe_output)
}

###########   Functions for machine learning ############################################################

# 1. function for train ensemble df. 
f_train_ensemble <- function (GX_Data,Resample_list,index){
  #Get Train DF
  train_ensemble_df<-f_train_test(GX_Data,Resample_list_results$DataPartition,index,T)
  #subset to predictors
  train_ensemble_df<-train_ensemble_df[,c("Phenotype",Resample_list$rfelist[[index]])]
  return (train_ensemble_df)
}



# 2. function for caret list. Machine Learning.
f_caret_list_ML <- function (GX_train,boot_n){
  
  #set seed
  set.seed(seed)
  #define indices
  index=createResample(GX_train$Phenotype, boot_n)
  print(index)
  #set control
  my_control <- trainControl(method="boot", 
                             number=boot_n,
                             index=index,
                             classProbs = TRUE,
                             summaryFunction=twoClassSummary,
                             savePredictions="final",
                             preProc=c("center", "scale"),
                             sampling="down")
  
  #set seed
  set.seed(seed)
  #Machine learning Cart List. 
  return(caretList(Phenotype~., 
                    data=GX_train, 
                    trControl=my_control,
                    metric=metric,
                    tuneList=ML_list2,
                    continue_on_fail=T))
}


# 3. function for caret stack. Blend Meta models. 
#Caret stack function
f_run_caret_stack <- function (model_list,ensemble_method="gbm",ensemble_tune=10){
  #save caret stack
  return(caretStack(
    model_list,
    method=ensemble_method,
    verbose=FALSE,
    tuneLength=ensemble_tune,
    metric="ROC",
    trControl=trainControl(
      method="boot",
      number=25,
      savePredictions="final",
      classProbs=TRUE,
      summaryFunction=twoClassSummary)
    )
  )
}

# 4. get caret list and stack results

f_save_results_1 <- function (results_resample,model_list=model_list,test_df,Sub_prefix=Sub_prefix){
  results_resample[["gx_testing"]] <- test_df
  results_resample[["caret_list"]]<- model_list
  results_resample[["caret_list_model_preds"]] <- lapply(model_list, predict, newdata=test_df)
  results_resample[["splom"]]<-splom(resamples(model_list))
  results_resample[["modelcor"]]<-modelCor(resamples(model_list))
  #save list for top level resample (initial train test split)
  save(results_resample, file=paste(output_dir,project_id,project_name,Sub_prefix,top_split,".rdata",sep=""), compress = T)
  return(results_resample)
}


f_save_results_2 <- function (results_resample,model_list=model_list,test_df,ensemble_model,Sub_prefix){
  results_resample[["ensemble_full"]]<-ensemble_model #save ensemble
  results_resample[["ensemble_summary"]]<-summary(ensemble_model) #save ensemble categoical
  results_resample[["ensemble_model_preds_cat"]]<-f_get_caret_stack_results(model_list,ensemble_model,test_df,probability = F)
  model_preds<-f_get_caret_stack_results(model_list,ensemble_model,test_df,probability = T) 
  results_resample[["ensemble_model_preds_probability"]]<-model_preds #save model preds probability
  results_resample[["ensemble_test_performance"]]<-caTools::colAUC(model_preds, test_df$Phenotype) #save comparision
  #save results
  save(results_resample, file=paste(output_dir,project_id,project_name,Sub_prefix,top_split,".rdata",sep=""), compress = T)
  return(results_resample)
}

# 5 function drawing on 1-4
#Function creating models and blend
f_caret_list_ensemble <- function (GX_DF=GX_DF,Resample_list_results=Resample_list_results,top_split=top_split,boot_n=boot_n,fold=x){

  #get train ensemble df
  train_ensemble_df<-f_train_ensemble(GX_DF,Resample_list_results,x)

  #Machine learning
  set.seed(seed)
  model_list<-f_caret_list_ML(train_ensemble_df,boot_n)  
  print(model_list)
  print(paste("Caret_list for fold",fold,"done.",sep=" "))
  ###save caret list
  #define test data
  testing<-f_train_test(GX_DF,Resample_list_results$DataPartition,x,F)

  # Output data caret list. 
  #save initial results
  results_output<-list()
  results_output<-f_save_results_1(results_output,model_list,test_df=testing,Sub_prefix)
  print(paste("Caret_list for fold",fold,"saved.",sep=" "))
  
  #create ensemble
  set.seed(seed)  
  ensemble_final<-f_run_caret_stack(model_list)
  print(paste("Caret_stack for fold",fold,"done.",sep=" "))  

  #create results output
  results<-f_save_results_2(results_output,model_list,test_df=testing,ensemble_final,Sub_prefix)
  print(paste("Caret_stack for fold",fold,"saved.",sep=" "))  
  return(results)
}


```

#Load Data
```{r Load data}

#Load
load(file=paste(data_dejong_dir,"Dejong_reduced_Gx_data_and_pheno.RData",sep=""))
load(file=paste(data_dir,"GX_DF_adj_data.Rdata",sep=""))


#Reduce Gene expression Dejong to mirror GAP. 
dejong_Fdata<-filter(GAP_Dejong_Full_Fdata,DeJong_GAPDJ==TRUE)

#Remove all HS and Loc
dejong_Fdata <- dejong_Fdata %>% 
  mutate(LOC_HS_DROP=ifelse( grepl("^LOC",TargetID),"DROP",
                             ifelse( grepl("^HS\\.",TargetID), "DROP","KEEP"))) 
dejong_Fdata<-filter(dejong_Fdata,LOC_HS_DROP == "KEEP")


#clean Dejong
GX_DF<-Gx_dejong %>% mutate(Phenotype=ifelse(Diagnosis == "control","Control","FEP"))
features<-dim(GX_DF)[2]
GX_DF<-GX_DF[,c(features,1:(features-1))]
GX_DF<-GX_DF[,-c(2)]


#Create Dataframe
GX_DF<-GX_DF[,c("Phenotype",dejong_Fdata$TargetID)] #Expression data with Phenotype as first column



#Centre and Scale. 
preProcValues <- preProcess(GX_DF, method = c("center", "scale"))
GX_DF <- predict(preProcValues, GX_DF)

dim(GX_DF) #3919 features
GX_DF[,1]

```

#Load Libraries
```{r load_libs, tidy=TRUE}
rm(list = ls())
dev.off()
library(plyr)
library(dplyr)
library(lubridate)
library(doMC)
library(caret)
library(reshape)
library(tableone)
library(stargazer)
library(mice)
library(caretEnsemble)
library(ggplot2)
library(VennDiagram)
library(WGCNA)
library(flashClust)
library(data.table)
```



#Functions
```{r define functions, tidy=TRUE}


# 6 Functions For reporting results: 
f_get_caret_stack_results <- function (caret_list_data,ensemble_data,test_df,probability=TRUE,Pheno="Control"){
  if (probability == TRUE){
    print("creating probability df")
    model_predi <- lapply(caret_list_data, predict, newdata=test_df, type="prob")
    model_predi <- lapply(model_predi, function(x) x[,Pheno])
    model_predi <- data.frame(model_predi)
    model_predi$ensemble <- predict(ensemble_data, newdata=test_df, type="prob")
    return(model_predi)
  }else{
    print("creating categorical df")
    model_predi <- lapply(caret_list_data, predict, newdata=test_df)
    model_predi <- data.frame(model_predi)
    model_predi$ensemble <- predict(ensemble_data, newdata=test_df)
    model_predi$Phenotype<-test_df[,"Phenotype"]
    return (model_predi)
  }
}

#Function for ConfusionMatrix
f_Confusion_matrix <- function (input_data,Prediction_cols,Pheno_col="Phenotype"){
  Confusiondata<-list()
  for (i in Prediction_cols){
    Confusiondata[[i]]<-confusionMatrix(input_data[,i], input_data[,Pheno_col], positive = "FEP")
  }
  return(Confusiondata)
}



#venn Diagram function
plotVennDia <- function(a, ...) {
    grid.newpage()
    if (length(a) == 1) {
        out <- draw.single.venn(likes(a), ...)
    }
    if (length(a) == 2) {
        out <- draw.pairwise.venn(likes(a[1]), likes(a[2]), likes(a[1:2]), ...)
    }
    if (length(a) == 3) {
        out <- draw.triple.venn(likes(a[1]), likes(a[2]), likes(a[3]), likes(a[1:2]), 
            likes(a[2:3]), likes(a[c(1, 3)]), likes(a), ...)
    }
    if (length(a) == 4) {
        out <- draw.quad.venn(likes(a[1]), likes(a[2]), likes(a[3]), likes(a[4]), 
            likes(a[1:2]), likes(a[c(1, 3)]), likes(a[c(1, 4)]), likes(a[2:3]), 
            likes(a[c(2, 4)]), likes(a[3:4]), likes(a[1:3]), likes(a[c(1, 2, 
                4)]), likes(a[c(1, 3, 4)]), likes(a[2:4]), likes(a), ...)
    }
    if (!exists("out")) 
        out <- "Oops"
    return(out)
}

#Venn Diagram helper fun
likes <- function(animals) {
    ppl <- allpredictorsUnique
    for (i in 1:length(animals)) {
        ppl <- subset(ppl, ppl[animals[i]] == T)
    }
    nrow(ppl)
}

likes(c("Gx","Gx_Scz","Gx_PRS"))


```




#Define Directories
```{r Define directories}
top_dir<-getwd()
data_dir <-"./P0_Characterise/output/"
data_dir0 <-"./data/"
data_dejong_dir<-"./P00_Characterise_Dejong/output/"
output_dir <-"./P61_Dejong_2way/output/"
figs_dir <-"./P61_Dejong_2way/figs/"
```



# Settings
```{r Define Cores and Seed}
#Allow 8 Cores
registerDoMC(cores = 8) 
#Set Seed
seed = 7
##### Variables
Number_of_Splits <- 10 #Number of splits
#Number_of_Splits <- 2 #Number of splits
Split_Percentage <- 0.8 #Split of data
project_id = "p61_"
project_name = "dejong_data_"
Sub_prefix = "_Step2_"
#Variables for Step 2
#set number of subsets to test
subsets <- c(1:30)*25
#subsets <- c(1:3)*25 
boot_n = 30


```

# Step 1: Load RFE data
```{r Feature Elimination Reporting}

####### load resamples
load(file=paste(output_dir,project_id,project_name,Sub_prefix,"_Resample_List",".rdata",sep=""))

####### Save Plots and Probes.


#Create List of new colnames
Colnames_Plots<-paste("Dataset_",c(1:10),sep="")
#make output list later dataframe.
fullplotdata<-list()
for (Split_n in 1:Number_of_Splits){
  #get data from plot into plotdata
  plotdata<-cbind(data.frame(Resample_list_results$plottestlist[Split_n][[1]]$panel.args[[1]]$y),data.frame(Resample_list_results$plottestlist[Split_n][[1]]$panel.args[[1]]$x))
  #Rename cols
  names(plotdata)<-c("Accuracy","Features")
  #Plot individually
  ptitle<-paste("Recursive Feature Elimination"," (Train Set ",Split_n,")",sep="")  
  ggplot(plotdata[1:30,], aes(x=Features,y=Accuracy, group=1)) +
    geom_line()+
    ggtitle(ptitle)  
  ggsave(paste(figs_dir,project_id,project_name,Sub_prefix,Split_n,"_RFE_linegraph",".png",sep=""))

  #add to overall list.
  fullplotdata[[Split_n]]<-plotdata[1:30,1]

}
#turn to dataframe.
fullplotdata<-data.frame(fullplotdata)
#Add colnames and rownames
colnames(fullplotdata)<-Colnames_Plots
rownames(fullplotdata)<-Resample_list_results$plottestlist[1][[1]]$panel.args[[1]]$x[1:30]
fullplotdata$Features<-Resample_list_results$plottestlist[1][[1]]$panel.args[[1]]$x[1:30]

#Make dataframe 1-10 with only Accuraccy. with x as colnames, remove last col.

#Save Dataframes
#RFE
plotRFE<-melt(fullplotdata, id="Features")
colnames(plotRFE)<-c("Features","Dataset","Accuracy")

#ggplots RFE 
ptitle<-paste("Dejong Recursive Feature Elimination"," of 10 Datasets",sep="")  
ggplot(data.frame(plotRFE), aes(x=Features,y=Accuracy)) +
  geom_line()+
  facet_wrap(~ Dataset, ncol = 2)+
  ggtitle(ptitle)  
ggsave(paste(figs_dir,project_id,project_name,Sub_prefix,"_ALL_Facet_RFE_linegraph",".png",sep=""))

ptitle<-paste("Dejong Recursive Feature Elimination"," of 10 Datasets",sep="")  
ggplot(data.frame(plotRFE), aes(x=Features,y=Accuracy, colour = Dataset  )) +
  geom_line()+
  ggtitle(ptitle)  
ggsave(paste(figs_dir,project_id,project_name,Sub_prefix,"_ALL_Single_RFE_linegraph",".png",sep=""))


#Calculate mean and standard error. To see if data is consistent. 
fullplotdata

#plot that data in ggplot2 line graph. 


#List of all probes in all datasets. Indicate present or not. Remove NAs, to find overlaps.  

####### cut down probes to number of samples. 
for (Split_n in 1:Number_of_Splits){ 
    split<-Resample_list_results$rfelist[[Split_n]]
    if (length(split) > dim(Resample_list_results[[1]])[1]){
      Resample_list_results$rfelist[[Split_n]]<-split[1:dim(Resample_list_results[[1]])[1]]
    }
}

Probe_list_res= Resample_list_results$rfelist
for (Split_n in 1:Number_of_Splits){ 
    split<-Probe_list_res[[Split_n]]
    Probe_list_res[[Split_n]]<-sort(split)
}
Probe_list_res

Reduce(intersect, Probe_list_res[c(1,3,10)])

####### Save Probes again and plot



```



# Step 3: Load ML data. And Output results
```{r ML data & Results Internal}
#Check How roboust the models are. 


####### Load data
full_data<-list() #empty list wrapper. 
#Makee into function
for (i in 1:Number_of_Splits){
  #fold
  x=i
  #set top split ID
  top_split = paste("Split_",x,sep="")
  print(top_split)
  load(paste(output_dir,project_id,project_name,Sub_prefix,top_split,".rdata",sep=""))
  full_data[[top_split]]<-results_resample
}



#Create Table of performance for all models. 
ResultsTable = list()
TableColOrder<-colnames(data.frame(full_data[[1]]$ensemble_test_performance))
for (i in 1:Number_of_Splits){
  #fold
  x=i
  #set top split ID
  top_split = paste("Split_",x,sep="")
  #get data into df
  tempdf = data.frame(full_data[[i]]$ensemble_test_performance)
  if (length(tempdf) != 7){
    #add to list
    tempdf$pcaNNet=NA
  }  
  rownames(tempdf) = top_split
  ResultsTable[[top_split]] = t(tempdf[,TableColOrder])  

} 
#turn list to df
ResultsTable<-data.frame(ResultsTable)
MLresults_table<-t(round(ResultsTable[,1:10], digits = 2))
rownames(MLresults_table)=paste("AUC_Data_",c(1:10),sep="")
write.csv(MLresults_table,paste(output_dir,project_id,project_name,Sub_prefix,"MLresults.csv",sep=""))


ResultsTable$Model<-rownames(ResultsTable)
#RFE
plot_models<-melt(ResultsTable,id="Model")
colnames(plot_models)<-c("Models","Dataset","AUC")

#Compare Performance with Dataset
ggplot(data.frame(plot_models), aes(x=Dataset,y=AUC, colour=Dataset)) +
  geom_boxplot(notch=F)+
  geom_jitter() + 
  coord_flip()+
  #facet_wrap(as.formula(paste("~", pfacets)))+
  #ggtitle(ptitle)  
ggsave(paste(figs_dir,project_id,project_name,Sub_prefix,"_ROC_vs_Dejong_splits",".png",sep=""))


#Compare Performance by model
ggplot(data.frame(plot_models), aes(x=Models,y=AUC, colour=Models)) +
  geom_boxplot(notch=F)+
  geom_jitter() + 
  coord_flip()+
  #facet_wrap(as.formula(paste("~", pfacets)))+
  #ggtitle(ptitle)  
ggsave(paste(figs_dir,project_id,project_name,Sub_prefix,"_ROC_vs_Dejong_models",".png",sep=""))





####### Predict Dejong Test


####### Plot Dejong Test results


####### Statistical Tests



####### Get weights for model building ensemble. 
full_data$Split_1$modelcor
summary(full_data$Split_1$ensemble_full)
full_data$Split_1$ensemble_full

####### Get Probes for models
#Make lists of predictors
varImp(full_data$Split_1$caret_list$glmnet, scale = FALSE)
varImp(full_data$Split_1$caret_list$rf, scale = FALSE)

varImp(full_data$Split_1$ensemble_full$ens_model, scale = FALSE)



# Get Probes and feature importance

# make list of overlap

# make venn diagram 

# make 





```


# Step 4: Load GAP Data and Predict
```{r GAP Predict 2 and 3 cat split}

####### Load GAP
load(file=paste(data_dir,"GX_DF_adj_data.Rdata",sep=""))
#load(file=paste(data_dir,"GX_DF_full_adj_data.Rdata",sep=""))

GX_DF_not_scaled<-GX_DF_adj[,1:27]
#Centre and Scale. 
preProcValues <- preProcess(GX_DF_adj, method = c("center", "scale"))
GX_DF_GAP <- predict(preProcValues, GX_DF_adj)
dim(GX_DF_GAP)
GX_DF_GAP[,1:27]<-GX_DF_not_scaled


####### Clean GAP data
Test_data_1 <-  GX_DF_GAP %>%
      mutate(ICD_DSM = ifelse(is.na(ICD_DSM),"Other_Psychosis",ICD_DSM))


f_get_caret_stack_results <- function (caret_list_data,ensemble_data,test_df,probability=TRUE,Pheno){
  if (probability == TRUE){
    print("creating probability df")
    model_predi <- lapply(caret_list_data, predict, newdata=test_df, type="prob")
    model_predi <- lapply(model_predi, function(x) x[,Pheno])
    model_predi <- data.frame(model_predi)
    model_predi$ensemble <- predict(ensemble_data, newdata=test_df, type="prob")
    return(model_predi)
  }else{
    print("creating categorical df")
    model_predi <- lapply(caret_list_data, predict, newdata=test_df)
    model_predi <- data.frame(model_predi)
    model_predi$ensemble <- predict(ensemble_data, newdata=test_df)
    model_predi$Phenotype<-test_df[,"Phenotype"]
    return (model_predi)
  }
}



###### Generate GAP results
ResultsTable_GAP = list()
ResultsList_GAP_allpatients = list()
TableColOrder<-colnames(data.frame(full_data[[1]]$ensemble_test_performance))
for (i in 1:Number_of_Splits){
  #set top split ID
  top_split = paste("Split_",i,sep="")
  #Get models for fold
  model_list<-full_data[[top_split]]$caret_list
  gbm_ensemble<-full_data[[top_split]]$ensemble_full
  #Get predictions for fold
  model_preds<-1-f_get_caret_stack_results (model_list,gbm_ensemble,Test_data_1,probability=TRUE,Pheno="Control")
  #Get class predictions
  model_preds_class<-f_get_caret_stack_results (model_list,gbm_ensemble,Test_data_1,probability=F,Pheno="Control")
  #Change Colnames
  model_preds_class$Phenotype=NULL
  colnames(model_preds_class)=paste(colnames(model_preds_class),"Categorical",sep="_")  
  # Into temp DF
  ResultsList_GAP_allpatients[[top_split]] = cbind(Test_data_1[,1:27],model_preds,model_preds_class)
  tempdf = data.frame(caTools::colAUC(model_preds, Test_data_1$Phenotype))
  # Add pcaNNet if missing
  if (length(tempdf) != 7){
    #add to list
    tempdf$pcaNNet=NA
  }  
  rownames(tempdf) = top_split
  ResultsTable_GAP[[top_split]] = t(tempdf[,TableColOrder])  
}

#turn list to df
ResultsTable_GAP<-data.frame(ResultsTable_GAP)
MLresults_table_GAP<-t(round(ResultsTable_GAP[,1:10], digits = 2))
rownames(MLresults_table_GAP)=paste("Train_Data_",c(1:10),sep="")
write.csv(MLresults_table_GAP,paste(output_dir,project_id,project_name,Sub_prefix,"MLresults_GAP.csv",sep=""))


#Results for all Patients GAP. In list. Save!
save(ResultsList_GAP_allpatients, file=paste(output_dir,project_id,project_name,Sub_prefix,"GAP_Patient_predictions_Saved.rdata",sep=""), compress = T)



###### Make Split 1 
#Function
#Function for Getting Accuracy Table
f_meta_confuse<-function(Input_Data,GAP_Data_subset,Dejong_split = "Split_1"){
  confuse_out<-f_Confusion_matrix(Input_Data,colnames(Input_Data)[35:41])
  #Make lists for main metrics
  temp_dfrows<-names(confuse_out)
  overall_list=list()
  for (i in 1:7){  
    overall_list[["overall"]][[temp_dfrows[i]]]=confuse_out[[temp_dfrows[i]]]$overall
    overall_list[["byClass"]][[temp_dfrows[i]]]=confuse_out[[temp_dfrows[i]]]$byClass
  }

  #Create final DF
  Split_temp_df<-rbind(data.frame(overall_list[["overall"]]),data.frame(overall_list[["byClass"]]))
  Split_temp_df<-data.frame(t(round(Split_temp_df, digits = 3)))
  Split_temp_df$GAP_Data<-GAP_Data_subset
  Split_temp_df$Dejong_data<-Dejong_split
  Split_temp_df$Method<-colnames(Input_Data)[28:34]
  return(Split_temp_df)
}

#Make Data frame for split 1
Split_1_Data<-ResultsList_GAP_allpatients$Split_1

## Full GAP Data
Full_GAP_Metrics_split_1<-f_meta_confuse(Split_1_Data,"Full")

## Remove other psychosis
Split_1_Data_NOP<-filter(Split_1_Data,ICD_DSM !="Other_Psychosis")
GAP_NOP_Metrics_split_1<-f_meta_confuse(Split_1_Data_NOP,"Control_Schizophrenia")

## Remove Schizophrenia
Split_1_Data_OP<-filter(Split_1_Data,ICD_DSM !="Schizophrenia")
GAP_OP_Metrics_split_1<-f_meta_confuse(Split_1_Data_OP,"Control_Other_Psychosis")

#Combine
full_Accuracy_Table<-rbind(Full_GAP_Metrics_split_1,GAP_NOP_Metrics_split_1,GAP_OP_Metrics_split_1)
#Sort
full_Accuracy_Table<-full_Accuracy_Table[,c(19:21,1,18,2:17)]
#Save
write.csv(full_Accuracy_Table,paste(output_dir,project_id,project_name,Sub_prefix,"Split_1_Confusion_Matrix_metrics.csv",sep=""))
#Small Table
full_Accuracy_Table







##### Make Bar Plots of data
#Make Plots function
f_boxplot_ML_gx <-function(inputd,xax,yax,col,plot_ylabel,pfacets,ptitle) {
  ggplot(inputd, aes_string(x=xax,y=yax, colour = col)) +
    #geom_point() +  
    geom_boxplot(notch=F)+
    geom_jitter() + 
    coord_flip()+
    labs(x = xax) +  labs(y = plot_ylabel)+
    #facet_wrap(as.formula(paste("~", pfacets)))+
    ggtitle(ptitle)  
}

plot_ylabel = "Ensemble predicted schizophrenia probability"

#2 Way Boxplot
f_boxplot_ML_gx(Split_1_Data,"Phenotype","ensemble","Phenotype",plot_ylabel,"","")
ggsave(paste(figs_dir,project_id,project_name,Sub_prefix,"_Split_1_Ensemble_Case_Control",".png",sep=""))
#3 Way Boxplot
f_boxplot_ML_gx(Split_1_Data,"ICD_DSM","ensemble","ICD_DSM",plot_ylabel,"","")
ggsave(paste(figs_dir,project_id,project_name,Sub_prefix,"_Split_1_Ensemble_3_Scz_Other_Control",".png",sep=""))

#Density plots for all models
title = "Density Plots Stratified by Control and Psychosis type"
ggplot(Split_1_Data, aes(ensemble, colour = ICD_DSM)) +
  geom_density(alpha=0.01)+
  ggtitle(title)

######################Density plots
#######All models
density_plots1=Split_1_Data[,c(1:34)]
density_plots2<-melt(density_plots1, id=c(names(density_plots1[,-c(28:34)])))
#Change colnames
colnames(density_plots2)<-c(names(density_plots1[,-c(28:34)]),"Model","Percentage")
#define X axis Label
plot_xlabel_density = "Predicted Schizophrenia probability from Dejong Models"
#Control vs FEP
#title = "Density Plots Stratified by Control and FEP"
ggplot(density_plots2, aes(Percentage, colour = Phenotype)) +
  geom_density(alpha=0.01)+
  facet_wrap(~ Model)+
  labs(x = plot_xlabel_density)
  #ggtitle(title)
ggsave(paste(figs_dir,project_id,project_name,Sub_prefix,"Density_FEP_Control",".png",sep=""))

#Control vs Schizophrenia vs Other Psychoses
#title = "Density Plots Stratified by Control and Psychosis type"
ggplot(density_plots2, aes(Percentage, colour = ICD_DSM)) +
  geom_density(alpha=0.01)+
  facet_wrap(~ Model)+
  labs(x = plot_xlabel_density)
  #ggtitle(title)
ggsave(paste(figs_dir,project_id,project_name,Sub_prefix,"Density_Scz_Other_Control",".png",sep=""))




####### Statistical Tests

##### Statistics
#Calculate Median Value for each ICD_DSM group
Split_1_Data %>% group_by(ICD_DSM) %>% summarise(median(ensemble))
#
t.test(filter(Split_1_Data,ICD_DSM != "Control")$ensemble~filter(Split_1_Data,ICD_DSM != "Control")$ICD_DSM)
fit <- aov(ensemble ~ ICD_DSM, data=Split_1_Data)


#Plots of Algorithm for all splits
gglist<-list()
for (i in 1:Number_of_Splits){
  #set top split ID
  top_split = paste("Split_",i,sep="")
  gglist[[top_split]]=ggplot(data = ResultsList_GAP_allpatients[[top_split]], aes(x = ICD_DSM, y=ensemble, colour = ICD_DSM, fill = ICD_DSM)) +
    geom_boxplot(alpha = 0)+
    geom_jitter(alpha = 0.3)+
    coord_flip()+
    facet_wrap(~Ethnicity)+
    ggtitle(paste(top_split,"GAP data Predictions","Glmnet","Model",sep=" "))
}
gglist





```

# Step 5: GAP data post hoc exploration
```{r GAP Post Hoc}



####### 1_Gx characterisation with phenotypes. 

##Categorical Variables
#1. Ethnicity
f_plots_posthoc <-function(inputd,xax,yax,col,pfacets,ptitle) {
  ggplot(inputd, aes_string(x=xax,y=yax, colour = col)) +
    #geom_point() +  
    geom_boxplot(notch=F)+
    geom_jitter() + 
    #coord_flip()+
    facet_wrap(as.formula(paste("~", pfacets)))+
    ggtitle(ptitle)  
}

Split_1_Data$ensemble
f_plots_posthoc(Split_1_Data,"ICD_DSM","ensemble","ICD_DSM","Ethnicity","Titleofplot")
plot_fun_gx(PhenoMC_Data,"ICD_DSM","Acc_6_Gx_PRS","ICD_DSM","Ethnicity","Titleofplot")

#2. Gender
f_plots_posthoc(Split_1_Data,"ICD_DSM","ensemble","ICD_DSM","Gender","Titleofplot")



#3. Smoking 
f_plots_posthoc(Split_1_Data,"ICD_DSM","ensemble","ICD_DSM","Tobacco","Titleofplot")

#4. Medication
f_plots_posthoc(filter(Split_1_Data,Phenotype!="Control"),"ICD_DSM","ensemble","ICD_DSM","Medication","Titleofplot")




## Continues Variables
#Create bins
?quantile
?cut

Split_1_Data$Cuts<-cut(Split_1_Data$ensemble,quantile(Split_1_Data$ensemble,probs = c(0, 20, 40, 60, 80,100)/100))
quantile(Split_1_Data$ensemble,probs())
quantile(x<-c(1:100,1:100),  probs = c(25, 50, 1, 2, 5, 10, 50, NA)/100)
quantile(x<-c(0:100,0:100)
quantile(Split_1_Data$ensemble,probs = c(0, 20, 40, 60, 80,100)/100)



#5. Age 
f_plots_posthoc(Split_1_Data,"Cuts","Age","Cuts","ICD_DSM","Titleofplot")
ggplot(Split_1_Data, aes(x=Cuts,y=Age, colour = ICD_DSM)) +
  geom_jitter() +  
  geom_boxplot(notch=F)+
  coord_flip()+
  ggtitle(title)



#6. PRS (not imputed.)
Split_1_Data_white<-filter(Split_1_Data,Ethnicity=="White")
Split_1_Data_white<-filter(Split_1_Data_white,Phenotype=="FEP")
Split_1_Data_white$Cuts<-cut(Split_1_Data_white$ensemble,quantile(Split_1_Data_white$ensemble,probs = c(0, 20, 40, 60, 80,100)/100))
f_plots_posthoc(Split_1_Data_white,"ICD_DSM","PRS_0.1","ICD_DSM","Cuts","Titleofplot")
Split_1_Data_white$Cuts

cor(Split_1_Data_white$ensemble,Split_1_Data_white$PanssScore)


#6. PANSS

#Filter out controls
Split_1_Data_nocon<-filter(Split_1_Data,ICD_DSM!="Control")


Split_1_Data_nocon$pcaNNet
#Select model data
pmodel<-"pcaNNet"

#get quantiles for cutting into equal groups
Pquantiles<-quantile(Split_1_Data_nocon[,pmodel], probs = c(0,0.2,0.4,0.6,0.8,1))
#round and 
quantCuts<-as.vector(round(Pquantiles, 2)*100)[-1]
#create cuts and add to DF
Split_1_Data_nocon$Accuracy<-cut(Split_1_Data_nocon[,pmodel],Pquantiles,labels=quantCuts,include.lowest = T)


pan<-c("PanssScore","PanssPositive","PanssNegative","PanssPsycho")
panCuts<-"Accuracy"
for(n in 1:length(pan)){
  PanssDF<-Split_1_Data_nocon
  Title_plot_temp<-paste(pan[n]," vs binned Accuracy of sample classification",sep="")
  print(f_plots_posthoc(PanssDF,panCuts,pan[n],panCuts,"ICD_DSM",Title_plot_temp))
}

PanssDF<-Split_1_Data_nocon
#PanssDF<-filter(PhenoMC_Data_nocon,Ethnicity == "White")
n=1
f_plots_posthoc(PanssDF,panCuts,pan[n],panCuts,"ICD_DSM","Full PANSS vs binned Accuracy of sample classification")
#ggsave(paste(figs_dir,project_id,project_name,"_",pan[n],"_1_Gx.png",sep=""))
n=2
f_plots_posthoc(PanssDF,panCuts,pan[n],panCuts,"ICD_DSM","PANSS Positive subscale vs binned Accuracy of sample classification")
#ggsave(paste(figs_dir,project_id,project_name,"_",pan[n],"_1_Gx.png",sep=""))
n=3
f_plots_posthoc(PanssDF,panCuts,pan[n],panCuts,"ICD_DSM","PANSS Negative subscale vs binned Accuracy of sample classification")
#ggsave(paste(figs_dir,project_id,project_name,"_",pan[n],"_1_Gx.png",sep=""))
n=4
f_plots_posthoc(PanssDF,panCuts,pan[n],panCuts,"ICD_DSM","PANSS Psychopathology subscale vs binned Accuracy of sample classification")
#ggsave(paste(figs_dir,project_id,project_name,"_",pan[n],"_1_Gx.png",sep=""))




n=2
anovaDF<-PanssDF[complete.cases(PanssDF[,pan[n]]),]
#make dfs 
corDFScz<-filter(anovaDF,ICD_DSM =="Schizophrenia")
corDFOPSy<-filter(anovaDF,ICD_DSM !="Schizophrenia")
#calculate correlations
cor(corDFScz$ensemble,corDFScz[,pan[n]])
cor(corDFOPSy$ensemble,corDFOPSy[,pan[n]])
PP_lm = lm(ensemble ~ Medication, data=corDFScz)
summary(PP_lm)
PP_lm2 = lm(ensemble ~ PanssPositive, data=corDFOPSy)
summary(PP_lm2)

corDFScz$Medication


ggplot(anovaDF, aes_string(x="ensemble",y=pan[n], colour = "ICD_DSM"))+
  #stat_summary(fun.data=mean_cl_normal) + 
  geom_smooth(method='lm') +
  geom_point()


###### Panss
#Make Plots function
ggplot(density_plots2, aes(Percentage, colour = ICD_DSM)) +
  geom_density(alpha=0.01)+
  facet_wrap(~ Model)+
  labs(x = plot_xlabel_density)
  #ggtitle(title)

# All models
density_plots2$PanssScore
anovaDF<-PanssDF[complete.cases(PanssDF[,pan[n]]),]
ggplot(density_plots2, aes(x=Percentage,y=PanssScore, colour = ICD_DSM)) +
  geom_point()+
  facet_wrap(~ Model)+
  #stat_summary(fun.data=mean_cl_normal)+
  geom_smooth(method='lm')
#All panss
Panss_plots1=Split_1_Data[,c(1:34)]
Panss_plots1=density_plots2
Panss_plots2<-melt(Panss_plots1, id=c(names(Panss_plots1[,-c(14:17)])))
colnames(Panss_plots2)
dim(Panss_plots2)
Panss_plots2[1:10,]
Panss_plots3<-Panss_plots2[complete.cases(Panss_plots2$value),]
colnames(Panss_plots3)
##
ggplot(Panss_plots3, aes(x=Percentage,y=value, colour = ICD_DSM)) +
  geom_point()+
  facet_wrap(~ variable+Model)+
  #stat_summary(fun.data=mean_cl_normal)+
  geom_smooth(method='lm')


ggplot(filter(Panss_plots3,Model=="ensemble" & variable !="PanssScore"), aes(x=Percentage,y=value, colour = ICD_DSM)) +
  geom_point()+
  facet_wrap(~ variable+Model)+
  #stat_summary(fun.data=mean_cl_normal)+
  geom_smooth(method='lm')

#Change colnames
colnames(density_plots2)<-c(names(density_plots1[,-c(28:34)]),"Model","Percentage")


  #labs(x = plot_xlabel_density)
  #ggtitle(title)




fit <- aov(PanssPositive ~ Accuracy, data=anovaDF)

plant.mod1 = lm(PanssPositive ~ Accuracy, data = corDFOPSy)
plant.mod1 = lm(PanssPsycho ~ Accuracy, data = corDFScz)
summary(plant.mod1)
str(anova(plant.mod1))
confint(plant.mod1)

corDFScz = data.frame(Fitted = fitted(plant.mod1),
  Residuals = resid(plant.mod1), Treatment = corDFScz$PanssPsycho)


?resid
#5. ICD and DSM for other psych
f_plots_posthoc(filter(Split_1_Data_nocon,ICD_DSM!="Schizophrenia"),"icd10","ensemble","icd10","Medication","Titleofplot")

ggplot(filter(Split_1_Data_nocon,ICD_DSM!="Schizophrenia"), aes(x=dsmiv,y=ensemble, colour=dsmiv)) +
  geom_boxplot(notch=F)+
  geom_jitter() + 
  coord_flip()+
  theme(
      axis.text.y=element_blank(),
      axis.ticks.y=element_blank(),)

ggplot(filter(Split_1_Data_nocon,ICD_DSM!="Schizophrenia"), aes(x=PanssPsycho,y=ensemble, colour=Medication)) +
  geom_point()+
  coord_flip()+
  facet_wrap(~ dsmiv)

ggplot(filter(Split_1_Data_nocon,ICD_DSM=="Schizophrenia"), aes(x=Gender,y=ensemble, colour=Ethnicity)) +
  geom_point()+
  coord_flip()+
  facet_wrap(~ Medication)



  #facet_wrap(as.formula(paste("~", pfacets)))+
  #ggtitle(ptitle)  
ggplot(filter(Split_1_Data_nocon,ICD_DSM!="Schizophrenia"), aes(x=icd10,y=ensemble, colour=icd10)) +
  geom_boxplot(notch=F)+
  geom_jitter() + 
  coord_flip()
ggplot(filter(Split_1_Data_nocon,ICD_DSM!="Schizophrenia"), aes(x=Medication,y=ensemble, colour=dsmiv)) +
  geom_point() + 
  coord_flip() 



```

# Step 6: Load IMPACT & Predict
```{r IMPACT}


```