---
title: "Machine Learning"
author: "DJL"
date: "02/10/2016"
output:
  html_document:
    toc: yes
    toc_float: yes
---

#Overview

**Aim**  
Create Machine learning models using GAP data. 


#Libraries
```{r load_libs, tidy=TRUE}
rm(list = ls())
dev.off()
library(plyr)
library(dplyr)
library(randomForest)
library(lubridate)
library(doMC)
library(caret)
library(reshape)
library(tableone)
```

#Functions
```{r define functions, tidy=TRUE}

#all machine learning models
ml_fun<- function(dataset) {
  # Linear Discriminant Analysis
  set.seed(seed)
  fit.lda <- train(Phenotype~., data=dataset, method="lda", metric=metric, preProc=c("center", "scale"), trControl=control)
  # Logistic Regression
  set.seed(seed)
  fit.glm <- train(Phenotype~., data=dataset, method="glm", metric=metric, trControl=control)
  # GLMNET
  set.seed(seed)
  fit.glmnet <- train(Phenotype~., data=dataset, method="glmnet", metric=metric, preProc=c("center", "scale"), trControl=control)
  # SVM Radial
  set.seed(seed)
  fit.svmRadial <- train(Phenotype~., data=dataset, method="svmRadial", metric=metric, preProc=c("center", "scale"), trControl=control, fit=FALSE)
  # SVM Poly
  set.seed(seed)
  fit.svmPoly <- train(Phenotype~., data=dataset, method="svmPoly", metric=metric, preProc=c("center", "scale"), trControl=control, fit=FALSE)
  # SVM Linear
  set.seed(seed)
  fit.svmLinear <- train(Phenotype~., data=dataset, method="svmLinear2", metric=metric, preProc=c("center", "scale"), trControl=control, fit=FALSE)
  # kNN
  set.seed(seed)
  fit.knn <- train(Phenotype~., data=dataset, method="knn", metric=metric, preProc=c("center", "scale"), trControl=control)
  # Naive Bayes
  set.seed(seed)
  fit.nb <- train(Phenotype~., data=dataset, method="nb", metric=metric, trControl=control)
  # C5.0
  set.seed(seed)
  fit.c50 <- train(Phenotype~., data=dataset, method="C5.0", metric=metric, trControl=control)
  # Random Forest
  set.seed(seed)
  fit.rf <- train(Phenotype~., data=dataset, method="rf", metric=metric, trControl=control)
  # Stochastic Gradient Boosting (Generalized Boosted Modeling)
  set.seed(seed)
  fit.gbm <- train(Phenotype~., data=dataset, method="gbm", metric=metric, trControl=control, verbose=FALSE)

  ##Make List of models
  modellist<-list(lda=fit.lda, logistic=fit.glm, glmnet=fit.glmnet,svmRad=fit.svmRadial,svmPoly=fit.svmPoly,svmLinear=fit.svmLinear, knn=fit.knn, nb=fit.nb,c50=fit.c50, rf=fit.rf, gbm=fit.gbm)
  modellist
}


#heatmap plotting function
heatmap_ml<- function(model="NA",x_ax="NA",x_title="NA", y_ax="NA",y_title="NA",color_metric="NA",h_title="NA",save_output="NA") {
  model_data<-model$results
  model_data[,x_ax]<-as.factor(model_data[,x_ax])
  model_data[,y_ax]<-as.factor(model_data[,y_ax])
  model_data_metric<-model_data[,color_metric]
  print(str(model_data))
  ggplot(data = model_data, aes_string(x=x_ax, y=y_ax, fill=color_metric))+
    geom_tile(color = "white")+
    scale_fill_gradient2(low = "red", high = "blue", mid = "white", 
      midpoint = mean(model_data_metric), limit = c(min(model_data_metric),max(model_data_metric)), space = "Lab", 
      name="") +
    theme_minimal()+ 
    theme(axis.text.x = element_text(angle = 90, vjust = 1, 
      size = 10, hjust = 1))+
    coord_fixed()+
    ggtitle(h_title) + xlab(x_title) + ylab(y_title)
  ggsave(save_output)
}

#find simple model. 
simple_model_fun<- function(ml_model,tol_percentage = 1, metric_sm=metric) {
    tolerance(ml_model$results, metric = metric_sm, tol = tol_percentage, maximize = TRUE)    
}


```


#Directories
```{r Define directories}
top_dir<-getwd()
data_dir <-"./P0_Characterise/output/"
data_dir0 <-"./data/"
output_dir <-"./P2_Hypothesis_Driven/output/"
figs_dir <-"./P2_Hypothesis_Driven/figs/"

#Pre and post fixes.
project_name = "Hypothesis_Driven"
project_id = "p2_2"

```




#Load Data
```{r Load data}

load(paste(data_dir,"Train_and_Test_data.Rdata",sep=""))
load(file=paste(output_dir,"RFE_model_results_hypothesis_free_data.Rdata",sep=""))


```

#Configure
```{r Define Cores and Seed}

#Allow 8 Cores
registerDoMC(cores = 8) 
#Set Seed
seed = 7
set.seed(seed)

#Control for algorithms
control <- trainControl(method="repeatedcv", number=10, repeats=10, sampling="down", savePredictions="all") ## Steve added sampling argument. READ!!

#Define Metric to choose best model
metric <- "Accuracy"

#Names of all predictors to be used. 
opt_rfepredictors<-predictors(rfe_output)


#input data frame
expressionRFE<-training_df[,c("Phenotype",opt_rfepredictors)]



```

# Machine Learning
```{r feature selection}

#Warning will use a lot of resources and take a long time. Output is a list of machine learning models. 
ml_models<-ml_fun(expressionRFE)

#Save Models
save(ml_models, file=paste(output_dir,"Classification_models.rdata",sep=""), compress = T)

```



# PLotting
```{r Plotting of results}

###########################Use classification_model_script_gap_and_impact.rmd


#extract accuracy Models
ml_resample<-resamples(ml_models)
Acc_results<-ml_resample$values[,grep("*Accuracy",colnames(ml_resample$values))]

## Plot 

#single point
s_title=
Accuracy_results<-sapply(Acc_results,mean)
accuracy_plot<-as.data.frame(Accuracy_results)
accuracy_plot<-as.data.frame(Accuracy_results)
accuracy_plot$Algorithm<-row.names(accuracy_plot)

s_title="Dotplot_comparing"
ggplot(accuracy_plot,
  aes(x=Accuracy_results,y=Algorithm,color=Algorithm)) +
  geom_point()+ 
  ggtitle("Average accuracy of 10x10-fold cross validation for 11 Models")
ggsave(paste(figs_dir,project_id,"_",s_title,"_",project_name,"_Free.png",sep=""))
results<-ml_resample

#all points
Accuracy_results<-ml_resample$values[,grep("*Accuracy",colnames(ml_resample$values))]
accuracy_plot<-Accuracy_results[,row.names(as.matrix(sort(sapply(Accuracy_results,mean),decreasing = F)))]
accuracy_plot$Datasets<-c("RFE(GAP)")
accuracy_plot2<-melt(accuracy_plot, id="Datasets")
colnames(accuracy_plot2)<-c("GeneLists","Algorithm","Accuracy")

table(accuracy_plot2[,3])
s_title="Dotplot_comparing_cv"
ggplot(accuracy_plot2,
  aes(x=Algorithm,y=Accuracy, colour = Algorithm)) +
  geom_point() + 
  geom_boxplot()+
  coord_flip()+
  ggtitle("Accuracy of 10x10-fold cross validation for 11 Models")
ggsave(paste(figs_dir,project_id,"_",s_title,"_",project_name,"_Free.png",sep=""))


```

#Tuning of top models Random. 
```{r Tuning}

#change project id
project_id = "p2_3"
#Define tune parameters and depth (careful, this can be really ineffective for large numbers of hyperparameters.)
tunecontrol <- trainControl(method="repeatedcv", number=10, repeats=5, sampling="down", savePredictions="all")
tunelength <- 20

#Run Parameter Search.
set.seed(seed)
RF_fit <- train(Phenotype~., data=expressionRFE, method="rf", metric=metric, trControl=tunecontrol,tuneGrid=expand.grid(.mtry=(1:8))) 
#RF_fit <- train(Phenotype~., data=expressionRFE, method="rf", metric=metric, trControl=tunecontrol,tuneLength=tunelength) 
set.seed(seed)
nb_fit <-train(Phenotype~., data=expressionRFE, method="nb", metric=metric, tuneLength=tunelength, trControl=tunecontrol)
set.seed(seed)
c50_fit <-train(Phenotype~., data=expressionRFE, method="C5.0", metric=metric, tuneLength=tunelength, trControl=tunecontrol)




#Plots
s_title="RF_tuning"
ggplot(RF_fit)+
  ggtitle("Random Forrest Grid Search (Accuracy)")
ggsave(paste(figs_dir,project_id,"_",s_title,"_",project_name,"_Free.png",sep=""))

s_title="c50_tuning"
ggplot(c50_fit)+
  ggtitle("c50 Grid Search (Accuracy)")
ggsave(paste(figs_dir,project_id,"_",s_title,"_",project_name,"_Free.png",sep=""))


```



#Find low complexity model Here we look for a balance between complexity and accuracy. 
```{r complexity vs accuracy}


#####   Find least complex model within 1 percent of top performance
simpleRF<-as.numeric(RF_fit$results[simple_model_fun(ml_model=RF_fit),][1,])

#### Simplefy 
set.seed(seed)
RF_fit_simple <- train(Phenotype~., data=expressionRFE, method="rf", metric=metric, trControl=tunecontrol,tuneGrid=expand.grid(.mtry=(simpleRF[1]))) 


#variable Importance
importance <- varImp(RF_fit_simple, scale=FALSE)
print(importance)
t_title="RF_model_simple"
write.table(print(importance$importance), file=paste(output_dir,project_id,"_",t_title,"_","varImp.csv",sep=""),row.names=T,quote=FALSE,sep = ",")

```


#Resample of top performers and top low complexity performers. 
```{r complexity vs accuracy}
High_Low_complexity_model_list<-list(RF_complex = RF_fit, RF_simple=RF_fit_simple)

#Summary and Plot. 
ml_resample<-resamples(High_Low_complexity_model_list)
resamps=ml_resample

```

#Compare best models
```{r Compare}
str(resamps)
#define names of models for plot
#Model_names<-c("RF_Complex","RF_Simple","GBM_Complex","GBM_Simple","svmPoly_Complex","svmPoly_Simple")
Model_names<-c("RF_Complex","RF_Simple")
#plot comparing models
Accuracy_results<-resamps$values[,grep("*Accuracy",colnames(resamps$values))]
colnames(Accuracy_results)<-Model_names
accuracy_plot<-Accuracy_results[,row.names(as.matrix(sort(sapply(Accuracy_results,mean),decreasing = F)))]
accuracy_plot$Datasets<-c("RFE(GAP)")
accuracy_plot2<-melt(accuracy_plot, id="Datasets")
colnames(accuracy_plot2)<-c("GeneLists","Algorithm","Accuracy")

accuracy_plot2

title_final_models<-"Comparision of High and Low Complexity Models"
s_title="Hi_Lo_complexity_model_comparision"
ggplot(accuracy_plot2,
       aes(x=Algorithm,y=Accuracy, colour = Algorithm)) +
  geom_point() + 
  geom_boxplot()+
  geom_jitter()+
  coord_flip()+
  ggtitle(title_final_models)
ggsave(paste(figs_dir,project_id,"_",s_title,"_",project_name,"_.png",sep=""))


s_title="Dotplot_comparing_cv"
ggplot(accuracy_plot2,
  aes(x=Algorithm,y=Accuracy, colour = Algorithm)) +
  geom_point() + 
  geom_boxplot()+
  coord_flip()+
  ggtitle("Accuracy of 10x10-fold cross validation for 11 Models")
ggsave(paste(figs_dir,project_id,"_",s_title,"_",project_name,"_Free.png",sep=""))
```

#Save all models for reference
```{r save}


#Save Models
save(High_Low_complexity_model_list, file=paste(P1_output_dir,"P1_3_High_Low_complexity_model_list.rdata",sep=""), compress = T)

```



#Validation
```{r Validation}

#Predictions
predict_fit<-predict(gbmFit, newdata = testing_df)
confusionMatrix(predict_fit, testing_df$Phenotype)

predict_fit<-predict(gbm_final, newdata = testing_df)
confusionMatrix(predict_fit, testing_df$Phenotype)


predict_fit<-predict(RF_search, newdata = testing_df)
confusionMatrix(predict_fit, testing_df$Phenotype)

predict_fit<-predict(RF_final, newdata = testing_df)
confusionMatrix(predict_fit, testing_df$Phenotype)


predict_fit<-predict(svmPolyFit2, newdata = testing_df)
confusionMatrix(predict_fit, testing_df$Phenotype)

predict_fit<-predict(svmPoly_final, newdata = testing_df)
confusionMatrix(predict_fit, testing_df$Phenotype)


```



## Check most important variables for GAP
```{r}

#use model to predict training data
predict_train_fit<-predict.train(RF_fit, newdata = testing_df)
confusionMatrix(predict_train_fit, testing_df$Phenotype)

#check variables
names(testing_df)[1:26]

#create object to be used from now on. 
full_data<-testing_df[,1:26]


#add rownames to predictions
tpredictions<-data.frame(predict_train_fit)
rownames(tpredictions)<-full_data$sampleID


#create test data with pheno predictions. 
model_test_pheno<-merge(tpredictions,full_data,by.x="row.names",by.y="sampleID")
## Make confusion matrix column
model_test_pheno<-model_test_pheno %>% mutate(ConfusionMatrix=ifelse(Phenotype == "FEP" & predict_train_fit=="control","FEP_misclassed",
                                            ifelse(Phenotype == "FEP" & predict_train_fit=="FEP","FEP_true",
                                            ifelse(Phenotype != "FEP" & predict_train_fit=="FEP","Control_misclassified","Control_true"))))
# Center and Scale PRS
model_test_pheno[19:27]<-scale(model_test_pheno[19:27])


```


## Create Table of variables
```{r}


#Create Table of demographics with 4 predicted groups.
t_title="RF_model_Table_CM_1"
listVars <- c("Gender","Age", "Ethnicity","BMI","Tobacco",names(model_test_pheno)[19:27])
catVars <- c("Ethnicity","Tobacco")
table1_full <- CreateTableOne(vars = listVars, data = model_test_pheno, factorVars = catVars,strata=c("ConfusionMatrix"),includeNA = T)
table1print<-print(table1_full)
write.table(table1print, file=paste(output_dir,project_id,"_",t_title,"_","Demographics.csv",sep=""),row.names = TRUE, col.names = TRUE,quote=FALSE,sep = "\t")
write.table(table1print, file=paste(output_dir,project_id,"_",t_title,"_","Demographics.csv",sep=""),row.names = TRUE, col.names = TRUE,quote=FALSE)

#Create Table of demographics with 4 predicted groups. 
t_title="RF_model_Table_CM_1_meds"
listVars2 <- c("Medication","dsmiv.opcrit","icd10.opcrit","PanssScore","PanssPositive","PanssNegative","PanssPsycho")
catVars2 <- c("Medication","dsmiv.opcrit","icd10.opcrit")
table2_full <- CreateTableOne(vars = listVars2, data = filter(model_test_pheno,Phenotype=="FEP"), factorVars = catVars2,strata=c("ConfusionMatrix"),includeNA = T)
table2print<-print(table2_full)
write.table(table2print, paste(output_dir,project_id,"_",t_title,"_","Demographics.csv",sep=""),row.names = TRUE, col.names = TRUE,quote=FALSE,sep = "\t")



```



## Create Table of variables
```{r}

dim(model_test_pheno)
FEP_data<-filter(model_test_pheno,Phenotype=="FEP")


SUMO3<-testing_df$SUMO3

FEP_data<-testing_df
FEP_data<-merge(tpredictions,FEP_data,by.x="row.names",by.y="sampleID")




FEP_data<-filter(FEP_data,Phenotype=="FEP")
FEP_data<-filter(FEP_data,Phenotype=="FEP")
FEP_data<-FEP_data[complete.cases(FEP_data$Pol_1_GAP_all_strict_excl_WTCCC2),]
FEP_data[19:27]<-scale(FEP_data[19:27])
corPRS_genes<-cor(FEP_data[,-c(1:26)], method = c("pearson"))

?sort
sort(corPRS_genes[1,],decreasing = T)["SUMO3"]


library(WGCNA)
#Pirooznia gene lists
Genesets_HD<-read.csv(paste(data_dir0,"GeneSetsMental_Pirooznia_2016.csv",sep=""))

SCZ_comp<-filter(Genesets_HD, Eclass=="Scz-composite")
PGC_SCZ<-filter(Genesets_HD, Eclass=="PGC_SCZ")
PGC_BP<-filter(Genesets_HD, Eclass=="PGC_BP")
PGC_MDD<-filter(Genesets_HD, Eclass=="PGC_MDD")

#Compare genesets
table(PGC_SCZ[,1]%in%SCZ_comp[,1])
table(PGC_BP[,1]%in%SCZ_comp[,1])
table(PGC_MDD[,1]%in%SCZ_comp[,1])

#GAP all probes.
background_GAP<-colnames(testing_df)[-c(1:26)]
length(background_GAP)
table(background_GAP%in%Genesets_HD$Gene_names)
table(background_GAP%in%SCZ_comp[,1])
table(background_GAP%in%PGC_SCZ[,1])
table(background_GAP%in%PGC_BP[,1])
table(background_GAP%in%PGC_MDD[,1])

#Hypothesis driven Probes
final_hd_probes<-background_GAP[background_GAP%in%Genesets_HD$Gene_names]


psycho_genes<-as.data.frame(cbind(final_hd_probes,final_hd_probes))
colnames(psycho_genes)<-c("final_hd_probes","Groups")
psycho_genes$Groups <- final_hd_probes%in%opt_rfepredictors
psycho_genes$Groups<-replace(psycho_genes$Groups, psycho_genes$Groups=="FALSE","background")
psycho_genes$Groups<-replace(psycho_genes$Groups, psycho_genes$Groups=="TRUE","Psychosis")

library(data.table)

setwd(top_dir)
setwd(data_dir0)
enrichments = userListEnrichment(psycho_genes$final_hd_probes,psycho_genes$Groups,fnIn=c("GeneSetsMental_Pirooznia_2016.csv"),catNmIn=c("Pirooznia"),useBrainLists=F,useBrainRegionMarkers = F,useBloodAtlases = F,useImmunePathwayLists = F,minGenesInCategory = 5)
#enrichments = userListEnrichment(all_probes$TargetID,all_probes$Groups,useBrainLists=T)
setwd(top_dir)
enpv<-enrichments$pValue
enrichment_probes<-unlist(lapply(enrichments$ovGenes,paste, collapse =";"))
enpv$Genes<-enrichment_probes
enpv<-enpv[order(enpv$InputCategories,enpv$Pvalues),]
enpvDT<-data.table(enpv)
#enpvDT<-enpvDT[Pvalues < 0.05 & NumOverlap > 5,.SD[],by=InputCategories]
##Select top 20, add pvalue < 0.05
enpvDT<-enpvDT[,.SD[1:20],by=InputCategories]
enpvDT

write.csv(as.data.frame(enpvDT),file=paste(P3_output_dir,"Supplementary_Table_9_User_list_enrichment_diff_expression_results.csv",sep=""),row.names=F)

```
