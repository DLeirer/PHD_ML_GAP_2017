---
title: "Machine Learning"
author: "DJL"
date: "02/10/2016"
output:
  html_document:
    toc: yes
    toc_float: yes
---

#Overview

**Aim**  
Create Machine learning models using GAP data. 


#Libraries
```{r load_libs, tidy=TRUE}
rm(list = ls())
dev.off()
library(plyr)
library(dplyr)
library(randomForest)
library(lubridate)
library(doMC)
library(caret)
library(reshape)
library(tableone)
library(stargazer)
library(mice)
```

#Functions
```{r define functions, tidy=TRUE}

#heatmap plotting function
heatmap_ml<- function(model="NA",x_ax="NA",x_title="NA", y_ax="NA",y_title="NA",color_metric="NA",h_title="NA",save_output="NA") {
  model_data<-model$results
  model_data[,x_ax]<-as.factor(model_data[,x_ax])
  model_data[,y_ax]<-as.factor(model_data[,y_ax])
  model_data_metric<-model_data[,color_metric]
  print(str(model_data))
  ggplot(data = model_data, aes_string(x=x_ax, y=y_ax, fill=color_metric))+
    geom_tile(color = "white")+
    scale_fill_gradient2(low = "red", high = "blue", mid = "white", 
      midpoint = mean(model_data_metric), limit = c(min(model_data_metric),max(model_data_metric)), space = "Lab", 
      name="") +
    theme_minimal()+ 
    theme(axis.text.x = element_text(angle = 90, vjust = 1, 
      size = 10, hjust = 1))+
    coord_fixed()+
    ggtitle(h_title) + xlab(x_title) + ylab(y_title)
  ggsave(save_output)
}

#find simple model. 
simple_model_fun<- function(ml_model,tol_percentage = 1, metric_sm=metric) {
    tolerance(ml_model$results, metric = metric_sm, tol = tol_percentage, maximize = TRUE)    
}

#helper Function for creation stratified by confusionmatrix result data frame when making tables of enviroment vs classification 
create_table_df<-function(input_data,use_columns,ml_data_predictions){
  #create object to be used from now on. 
  full_data<-input_data[,1:use_columns]
  #add rownames to predictions
  tpredictions<-data.frame(ml_data_predictions)
  rownames(tpredictions)<-full_data$sampleID


  #create test data with pheno predictions. 
  model_test_pheno<-merge(tpredictions,full_data,by.x="row.names",by.y="sampleID")
  ## Make confusion matrix column
  model_test_pheno<-model_test_pheno %>% mutate(ConfusionMatrix=ifelse(Phenotype == "FEP" & ml_data_predictions=="Control","FEP_misclassed",
                                            ifelse(Phenotype == "FEP" & ml_data_predictions=="FEP","FEP_true",
                                            ifelse(Phenotype != "FEP" & ml_data_predictions=="FEP","Control_misclassified","Control_true"))))
  # Center and Scale PRS
  model_test_pheno[20:28]<-scale(model_test_pheno[20:28])
  return (model_test_pheno)
}


# Function for making tables of confusion matrix stratified dataframes of ml models
table_fun_ml<- function(mldata,out_name_id,prs_col=(20:28)){
  #output name of model define
  t_title=out_name_id
  latex="_latex"
  latex="_latex"
  #Create Table of demographics with 4 predicted groups.
  listVars <- c("Gender","Age", "Ethnicity","BMI","Tobacco","ICD_DSM",names(mldata)[prs_col])
  catVars <- c("Ethnicity","Tobacco","ICD_DSM")
  table1 <- CreateTableOne(vars = listVars, data = mldata, factorVars = catVars,strata=c("ConfusionMatrix"),includeNA = T)
  table1print<-print(table1, quote = FALSE, noSpaces = TRUE, printToggle = FALSE)
  write.csv(table1print, file=paste(output_dir,project_id,"not_latex","_",t_title,"_","Table_CM_1_Demographics.csv",sep=""),row.names = TRUE, col.names = TRUE,quote=FALSE,sep=",")

  
  #Create Table of demographics with 4 predicted groups. 
  listVars2 <- c("Medication","dsmiv","icd10","ICD_DSM","PanssScore","PanssPositive","PanssNegative","PanssPsycho")
  catVars2 <- c("Medication","dsmiv","icd10","ICD_DSM")
  table2_full <- CreateTableOne(vars = listVars2, data = filter(mldata,Phenotype=="FEP"), factorVars = catVars2,strata=c("ConfusionMatrix"),includeNA = T)
  table2print<-print(table2_full,quote = FALSE, noSpaces = TRUE, printToggle = FALSE)
  write.csv(table2print, paste(output_dir,project_id,"not_latex","_",t_title,"_","Table_CM_1_meds_Demographics.csv",sep=""),row.names = TRUE, col.names = TRUE,quote=FALSE,sep = ",")
  
  #stargazer latex tables
  table1sg<-stargazer(table1print[,1:5],summary=FALSE, rownames=T)
  write.csv(table1sg,paste(output_dir,project_id,latex,"_",t_title,"_","Table_CM_1_Demographics.csv",sep=""),sep="",row.names=F,col.names = F)
  table2sg<-stargazer(table2print[,1:3],summary=FALSE, rownames=T)
  write.csv(table2sg,paste(output_dir,project_id,latex,"_",t_title,"_","Table_CM_1_meds_Demographics.csv",sep=""),sep="",row.names=F,col.names = F)
}

```


#Directories
```{r Define directories}
top_dir<-getwd()
data_dir <-"./P0_Characterise/output/"
data_dir0 <-"./data/"
data_dejong_dir<-"./P00_Characterise_Dejong/output/"
output_dir <-"./P51_GAP_2way/output/"
figs_dir <-"./P51_GAP_2way/figs/"


#Pre and post fixes.
project_name = "GAP_Train_2way"
project_id = "p51_"

```




#Load Data
```{r Load data}


load(file=paste(data_dejong_dir,"Dejong_reduced_Gx_data_and_pheno.RData",sep=""))
load(file=paste(data_dir,"GX_DF_adj_data.Rdata",sep=""))
#Genesets_HD<-read.csv(paste(data_dir0,"GeneSetsMental_Pirooznia_2016.csv",sep=""))



```

#Clean Data
```{r Clean Data}
#Reduce Gene expression GAP to mirror Dejong. 
GAP_Fdata<-filter(GAP_Dejong_Full_Fdata,GAP_GAPDJ==TRUE)

#Remove all HS and Loc
GAP_Fdata <- GAP_Fdata %>% 
  mutate(LOC_HS_DROP=ifelse( grepl("^LOC",TargetID),"DROP",
                       ifelse( grepl("^HS\\.",TargetID), "DROP","KEEP"))) 
GAP_Fdata<-filter(GAP_Fdata,LOC_HS_DROP == "KEEP")
table(GAP_Fdata$LOC_HS_DROP)


table(GAP_Fdata$TargetID%in%colnames(Gx_dejong)) #should all be true. 

Gx_DF_1_locHS<-GX_DF_adj[,c("Phenotype",GAP_Fdata$TargetID)]
colnames(Gx_dejong)[1]<-"Phenotype"

table(colnames(Gx_DF_1_locHS)%in%colnames(Gx_dejong)) #All equal?



### Remove High correlation probes. 
#make dataset of features that are not probes for backup and later use.


cor_fun<- function(gene_exprs_DF,cor_cutoff=0.8) {
  # find highly correlated probes
  correlationMatrix <- cor(gene_exprs_DF)
  # find attributes that are highly corrected (ideally >0.75)
  findCorrelation(correlationMatrix, cutoff=cor_cutoff)

}


#ONLY KEEP PHENOTYPE
Gx_DF_1_locHS[1:10,1:10]
#find highly correlated probes set to 80 by default.
highlyCorrelated<-cor_fun(Gx_DF_1_locHS[,-c(1)],cor_cutoff=0.75)
highlyCorrelated


# remove highly correlated probes
Gx_DF_2_cor<-Gx_DF_1_locHS[,-c(highlyCorrelated+1)]##+1 is for phenotype col. Adds 1 to each number. 
dim(Gx_DF_2_cor)
dim(Gx_DF_1_locHS)


#Low Variance Probes removed
Gx_vars<-apply(Gx_DF_2_cor[,c(-1)], 2, function(x) var(x,))
Gx_vars_quant<-quantile(Gx_vars, c(.1,.2,.3,.4,.5))
Gx_vars_names<-names(which(Gx_vars > Gx_vars_quant[2]))
Gx_DF_3_var<-Gx_DF_2_cor[,c("Phenotype",Gx_vars_names)]

dim(Gx_DF_1_locHS)
dim(Gx_DF_2_cor)
dim(Gx_DF_3_var)

#Diff expression List






### Other
PGC_SCZ<-filter(Genesets_HD, Eclass=="PGC_SCZ")
final_SCZ_probes<-Gx_DF_1_locHS[c(TRUE,colnames(Gx_DF_1_locHS)%in%PGC_SCZ$Gene_names)]
dim(final_SCZ_probes)


```


#Configure
```{r Define Cores and Seed}

#Allow 8 Cores
registerDoMC(cores = 8) 
#Set Seed
seed = 7
set.seed(seed)

#Control for algorithms
control <- trainControl(method="repeatedcv", number=5, repeats=3, sampling="down", savePredictions="all") ## Steve added sampling argument. READ!!

#Define Metric to choose best model
metric <- "Accuracy"

modelID<-c("lda","glm","gbm","glmnet","nb","knn","svmLinear2","svmPoly","svmRadial","rf","C5.0","parRF","elm","nnet","avNNet","pcaNNet","xgbTree","AdaBag","AdaBoost.M1")
#modelID<-c("lda","glm","gbm","glmnet","nb","knn","rf","parRF","svmLinear2","svmPoly","svmRadial","pcaNNet","avNNet","nnet","C5.0","elm","AdaBag")
#modelID<-c("lda","glm","gbm","glmnet","nb","knn","svmLinear2","svmPoly")


```

# Machine Learning
```{r Machine Learning}

#Machine Learning
List_of_models<-list()
for(i in 1:length(modelID)){
  tryCatch({
    print(modelID[i])
    List_of_models[[modelID[i]]]<-"NA: Probable error"
    set.seed(seed)
    List_of_models[[modelID[i]]] <- train(Phenotype~., data=Gx_DF_input, method=modelID[i], metric=metric, preProc=c("center", "scale"), trControl=control)
    print(List_of_models[[modelID[i]]])
    temp<-List_of_models[[modelID[i]]]
    save(temp, file=paste(output_dir,project_id,project_name,"_",modelID[i],".rdata",sep=""), compress = T)    
  }, 
  error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}

save(List_of_models, file=paste(output_dir,project_id,project_name,"_all_models",".rdata",sep=""), compress = T)

```

#Configure
```{r Define Cores and Seed}

#Allow 8 Cores
registerDoMC(cores = 8) 
#Set Seed
seed = 7
set.seed(seed)

#Control for algorithms
control <- trainControl(method="repeatedcv", number=5, repeats=3, sampling="down", savePredictions="all") ## Steve added sampling argument. READ!!

#Define Metric to choose best model
metric <- "Accuracy"

modelID<-c("lda","glm","gbm","glmnet","nb","knn","svmLinear2","svmPoly","svmRadial","rf","C5.0","parRF","elm","nnet","avNNet","pcaNNet","AdaBag","AdaBoost.M1")
#modelID<-c("lda","glm","gbm","glmnet","nb","knn","rf","parRF","svmLinear2","svmPoly","svmRadial","pcaNNet","avNNet","nnet","C5.0","elm","AdaBag")
#modelID<-c("lda","glm","gbm","glmnet","nb","knn","svmLinear2","svmPoly")


```

# Machine Learning 1
```{r Machine Learning}


#Control for algorithms
control <- trainControl(method="repeatedcv", number=5, repeats=3, sampling="down", savePredictions="final") ## Steve added sampling argument. READ!!
#For saving files. 
Sub_prefix = "_R1_"
input_data=Gx_DF_1_locHS
dim(input_data)
modelID<-c("lda","glm","gbm","glmnet","nb","knn","svmLinear2","svmPoly","svmRadial","rf","C5.0","parRF","elm","nnet","avNNet","pcaNNet","AdaBag","AdaBoost.M1")


#Machine Learning
List_of_models<-list()
for(i in 1:length(modelID)){
  tryCatch({
    print(modelID[i])
    List_of_models[[modelID[i]]]<-"NA: Probable error"
    set.seed(seed)
    List_of_models[[modelID[i]]] <- train(Phenotype~., data=input_data, method=modelID[i], metric=metric, preProc=c("center", "scale"), trControl=control)
    print(List_of_models[[modelID[i]]])
    temp<-List_of_models[[modelID[i]]]
    save(temp, file=paste(output_dir,project_id,project_name,Sub_prefix,"_",modelID[i],".rdata",sep=""), compress = T)    
  }, 
  error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}

save(List_of_models, file=paste(output_dir,project_id,project_name,Sub_prefix,"_all_models",".rdata",sep=""), compress = T)


```
# Machine Learning 2
```{r Machine Learning}

#Control for algorithms
control <- trainControl(method="repeatedcv", number=5, repeats=3, sampling="down", savePredictions="final") ## Steve added sampling argument. READ!!
#For saving files. 
Sub_prefix = "_R2_"
input_data=Gx_DF_2_cor
dim(input_data)
modelID<-c("lda","glm","gbm","glmnet","nb","knn","svmLinear2","svmPoly","svmRadial","rf","C5.0","parRF","elm","nnet","avNNet","pcaNNet","AdaBag","AdaBoost.M1")




#Machine Learning
List_of_models<-list()
for(i in 1:length(modelID)){
  tryCatch({
    print(modelID[i])
    List_of_models[[modelID[i]]]<-"NA: Probable error"
    set.seed(seed)
    List_of_models[[modelID[i]]] <- train(Phenotype~., data=input_data, method=modelID[i], metric=metric, preProc=c("center", "scale"), trControl=control)
    print(List_of_models[[modelID[i]]])
    temp<-List_of_models[[modelID[i]]]
    save(temp, file=paste(output_dir,project_id,project_name,Sub_prefix,"_",modelID[i],".rdata",sep=""), compress = T)    
  }, 
  error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}

save(List_of_models, file=paste(output_dir,project_id,project_name,Sub_prefix,"_all_models",".rdata",sep=""), compress = T)

```

# Machine Learning 3
```{r Machine Learning}

#Control for algorithms
control <- trainControl(method="repeatedcv", number=5, repeats=3, sampling="up", savePredictions="final") ## Steve added sampling argument. READ!!
#For saving files. 
Sub_prefix = "_R3_"
input_data=Gx_DF_3_var
dim(input_data)
modelID<-c("lda","glm","rf","glmnet","nb","knn","svmRadial","C5.0","gbm","elm","pcaNNet","svmLinear2","svmPoly","avNNet","parRF","nnet","AdaBag","AdaBoost.M1")
#modelID<-c("glmnet","knn","rf")

tuneLengthVar=10


#Machine Learning
List_of_models<-list()
for(i in 1:length(modelID)){
  tryCatch({
    print(modelID[i])
    List_of_models[[modelID[i]]]<-"NA: Probable error"
    set.seed(seed)
    List_of_models[[modelID[i]]] <- train(Phenotype~., data=input_data, method=modelID[i], metric=metric, preProc=c("center", "scale"),tuneLength = tuneLengthVar, trControl=control)
    print(List_of_models[[modelID[i]]])
    temp<-List_of_models[[modelID[i]]]
    save(temp, file=paste(output_dir,project_id,project_name,Sub_prefix,"_",modelID[i],".rdata",sep=""), compress = T)    
  }, 
  error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}

save(List_of_models, file=paste(output_dir,project_id,project_name,Sub_prefix,"_all_models",".rdata",sep=""), compress = T)

```


# Machine Learning 4
```{r Machine Learning}



#Control for algorithms
control <- trainControl(method="repeatedcv", number=5, repeats=3, sampling="down", savePredictions="final") ## Steve added sampling argument. READ!!
#For saving files. 
Sub_prefix = "_R4_"
input_data=final_SCZ_probes
dim(input_data)
#modelID<-c("lda","glm","gbm","glmnet","nb","knn","svmLinear2","svmPoly","svmRadial","rf","C5.0","parRF","elm","nnet","avNNet","pcaNNet","AdaBag","AdaBoost.M1")
modelID<-c("lda","glm","gbm","glmnet","nb","knn","svmRadial","rf","C5.0","elm","pcaNNet")

?trainControl

#Machine Learning
List_of_models<-list()
for(i in 1:length(modelID)){
  tryCatch({
    print(modelID[i])
    List_of_models[[modelID[i]]]<-"NA: Probable error"
    set.seed(seed)
    List_of_models[[modelID[i]]] <- train(Phenotype~., data=input_data, method=modelID[i], metric=metric, preProc=c("center", "scale"), trControl=control)
    print(List_of_models[[modelID[i]]])
    temp<-List_of_models[[modelID[i]]]
    save(temp, file=paste(output_dir,project_id,project_name,Sub_prefix,"_",modelID[i],".rdata",sep=""), compress = T)    
  }, 
  error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}

save(List_of_models, file=paste(output_dir,project_id,project_name,Sub_prefix,"_all_models",".rdata",sep=""), compress = T)

```


# Randomized labels. and ROC RSME testing.
```{r Plotting of results}


#Ranom labels
List_of_DFs<-list()
randomN<-c(1:10)
for (R in 1:10) {
  set.seed(randomN[R])
  input_data_R<-input_data
  input_data_R[,1]<-sample(input_data[,1])
  List_of_DFs[[R]]<-input_data_R
}



List_of_DFs[[R]]

RNum<-1

List_of_models2<-list()
for(i in 1:length(modelID)){
  tryCatch({
    print(modelID[i])
    List_of_models2[[modelID[i]]]<-"NA: Probable error"
    set.seed(seed)
    List_of_models2[[modelID[i]]] <- train(Phenotype~., data=List_of_DFs[[RNum]], method=modelID[i], metric=metric, preProc=c("center", "scale"), trControl=my_control)
    print(List_of_models2[[modelID[i]]])
  }, 
  error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}

modelID<-c("lda","glm","gbm","glmnet","nb","knn","svmRadial","rf","C5.0","elm","pcaNNet")
#Metrics
my_control <- trainControl(method="repeatedcv", number=5, repeats=2, sampling="down",classProbs = TRUE,summaryFunction=twoClassSummary,savePredictions="final")
#my_control <- trainControl(method="repeatedcv", number=5, repeats=2, sampling="down",classProbs = FALSE,summaryFunction=twoClassSummary,savePredictions="final")
#Metric2 = "RSME"
#Metric2 = "AUC"
Metric2 = "Accuracy"


input_data_test<-input_data[1:100,1:50]

List_of_models2<-list()
for(i in 1:length(modelID)){
  tryCatch({
    print(modelID[i])
    List_of_models2[[modelID[i]]]<-"NA: Probable error"
    set.seed(seed)
    List_of_models2[[modelID[i]]] <- train(Phenotype~., data=input_data_test, method=modelID[i], metric=Metric2, preProc=c("center", "scale"), trControl=my_control)
    print(List_of_models2[[modelID[i]]])
  }, 
  error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}



RSME_list
AUC_list
Accuracy_list


```



# Machine Learning Test
```{r Machine Learning}



modelID<-c("lda","glm","gbm","glmnet","nb","knn","svmLinear2","svmPoly","svmRadial","rf","C5.0","parRF","elm","pcaNNet")

#Machine Learning
List_of_models<-list()
for(i in 1:length(modelID)){
  tryCatch({
    print(modelID[i])
    List_of_models[[modelID[i]]]<-"NA: Probable error"
    set.seed(seed)
    List_of_models[[modelID[i]]] <- train(Phenotype~., data=Gx_DF_input, method=modelID[i], metric=metric, preProc=c("center", "scale"), trControl=control)
    print(List_of_models[[modelID[i]]])
    temp<-List_of_models[[modelID[i]]]
    save(temp, file=paste(output_dir,project_id,project_name,"_",modelID[i],".rdata",sep=""), compress = T)    
  }, 
  error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}

save(List_of_models, file=paste(output_dir,project_id,project_name,"_all_models",".rdata",sep=""), compress = T)

```


######Below Here is Just reference. DO not run. ################################################################################################################

#Imputation (PRS + Tobacco) + Demographic factors
```{r Load data}
##### Fix Polygenic Risk Score
#Set Seed
seed = 7
set.seed(seed)

#Factors of demographics
fa_ICD_DSM<-GX_DF_adj$ICD_DSM
fa_ICD_DSM[is.na(fa_ICD_DSM)]<- "Other_Psychosis"
GX_DF_adj$ICD_DSM<-fa_ICD_DSM
fa_Pheno <-as.factor(GX_DF_adj$Phenotype)
fa_Gender <-as.factor(GX_DF_adj$Gender)
fa_Ethnicity <-as.factor(GX_DF_adj$Ethnicity)
fa_Tobacco <-as.factor(GX_DF_adj$Tobacco)
#Model Matrix
design = model.matrix(~fa_Gender+fa_Ethnicity)  

#####Impute PRS
imputedesign = model.matrix(~fa_ICD_DSM+fa_Ethnicity)  #imputation factors

#create dataframe for input into impute
PRS_full_impute<-cbind(GX_DF_adj[,c("Phenotype","Ethnicity","ICD_DSM","PRS_0.1","sampleID")],imputedesign[,2:6])

#Impute with KNN using preprocess.
set.seed(seed)
ImputePCA<-preProcess(PRS_full_impute,method= c("knnImpute"))

#Get NAs
PRS_NAs<-PRS_full_impute[is.na(PRS_full_impute$PRS_0.1),]

#Predict 
resultspred<-cbind(predict(ImputePCA, PRS_full_impute)[4],PRS_full_impute[c(1:3,5)])

#Check all equal
all.equal(GX_DF_adj$sampleID[c(2:280,1)],resultspred$sampleID[c(2:280,1)])

#Prs back in original DF
GX_DF_adj$PRS_0.1<-resultspred$PRS_0.1

resultsNA<-resultspred[resultspred$sampleID%in%PRS_NAs$sampleID,]
resultspred$Imputed<-ifelse(resultspred$sampleID%in%PRS_NAs$sampleID,"Imputed", "Real")

#Make Plots
#imputed  vs PRS
title = "PRS_imputed_vs_real"
ggplot(data = resultspred, 
       aes(x = ICD_DSM, y=PRS_0.1  , colour = Imputed)) +
  geom_jitter() +
  geom_boxplot()+
  facet_wrap(~ Ethnicity)+
  ggtitle(title)
ggsave(paste(figs_dir,project_id,project_name,title,".png",sep=""))


```


####Define all 8 models with predictors 
```{r Create input dataframes for models}
#Define all 8 models with predictors 
Gx <-GX_DF_adj[,-c(1:3,5:27)]
Gx_Scz<-Gx[,c("Phenotype",names(GX_DF_adj)[names(GX_DF_adj)%in%Genesets_HD$Gene_names])]
PRS<-GX_DF_adj[,c(4,24)]  
Demographics<-cbind(GX_DF_adj[,c(4,6)],design[,2:5])
PRS_Demo<-cbind(GX_DF_adj[,c(4,6,24)],design[,2:5])
Gx_PRS <- cbind(PRS,GX_DF_adj[,-c(1:27)])
Gx_Demo <- cbind(Demographics,GX_DF_adj[,-c(1:27)])
Gx_Demo_PRS <- cbind(PRS_Demo,GX_DF_adj[,-c(1:27)])

#list of all model predictors
predictorlists<-list(Gx,Gx_Scz,PRS,Demographics,PRS_Demo,Gx_PRS,Gx_Demo,Gx_Demo_PRS)

#vector of model ids
modelID<-c("1_Gx","2_Gx_Scz","3_PRS","4_Demographics","5_PRS_Demo","6_Gx_PRS","7_Gx_Demo","8_Gx_Demo_PRS")


```


